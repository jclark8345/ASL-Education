# ASL-Education
American Sign Language (ASL) recognition algorithm/education system implemented through the use of Leap Motion Controller. The Leap motion Controller is an optical hand tracking module that captures the movements of the user's hands. This type of controller makes interaction with digital systems natural and effortless.

## Contents

- [Project Introduction](#project-introduction)
- [File Directory](#file-directory)
- [Data](#data)
- [Results](#results)
- [References](#references)

## Project Introduction

The goal of this project was to establish an interaction between the user, the Leap Motion controller and the javascript program, ultimately building a system that teaches a user the first 10 ASL digits. The system challenged the user to sign an ASL digit; detect whether they are; tell the user whether they are succeeding or not; and determine, after several seconds, whether they have succeeded or failed. Digit detection occurred through the use of the k-nearest neighbors (kNN) algorithm trained on cleaned/normalized data from all students in the class. Principles of human computer interaction, such as object consistency and cognitive psychology, sought to gamify the system to minimize the time while maximizing the education from the ASL system.

## File Directory

    - PredictGesture.html
    - PredictGesture.js
    - Record.html
    - Record.js
    - PrepareToDraw.js

## Data

## Results

## References

    - Lavamagh, S., Luxton-Reiller, A., Wuenscje, B., Plimmer, B. (2017). A systematic review of Virtual Reality in education. *Themes in Science and Technology Education*, 10(2), 85-119.


